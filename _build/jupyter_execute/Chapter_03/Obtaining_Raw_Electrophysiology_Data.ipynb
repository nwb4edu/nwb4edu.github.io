{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining  Electrophysiology Data from the AllenSDK\n",
    " \n",
    "The [Visual Coding - Neuropixels dataset from the Allen Institute of Brain Sciences](https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels) records spiking activity in the visual system of the mouse brain. At the time of writing, this dataset contains a total of 58 experiment sessions from Neuropixels probes in the cortex, hippocampus, and thalamus. There are three different trangenic mouse lines used in the experiments alongside the wild-type mice, which mark three different inhibitory cell types. The stimuli presented in this dataset range from natural scenes to drifting gratings. \n",
    "\n",
    "In this chapter you will learn how to download and sort through the Neuropixels dataset. Once you learn the basics, you will learn how to perform possible analyses to explain the neural activity within, as well as how to use optogenetics to identify different cell types within the data. \n",
    "\n",
    "This section will teach you how to interact with the Allen Institute Neuropixels dataset, specifically how to download experimental sessions, return processed data, and subset your data to contain only brain regions you are interested in. \n",
    "\n",
    "First things first, let's make sure you have the AllenSDK installed. See the [Allen Institute website](https://alleninstitute.github.io/AllenSDK/install.html) for information on installing it, otherwise, the cell below will do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allensdk already installed.\n"
     ]
    }
   ],
   "source": [
    "# This will ensure that the AllenSDK is installed.\n",
    "# If not, it will install it for you.\n",
    "try:\n",
    "    import allensdk\n",
    "    if allensdk.__version__ == '2.11.2':\n",
    "        print('allensdk already installed.')\n",
    "    else:\n",
    "        print('incompatible version of allensdk installed')\n",
    "except ImportError as e:\n",
    "    !pip install allensdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first need to import the `EcephysProjectCache` from the Allen SDK and create an instance of the class. The class is used to download the metadata and data for all sessions in the Neuropixels dataset. For the full list of methods, please visit the `allensdk.brain_observatory.ecephys.ecephys_project_cache` module documentation on the <a href = 'https://allensdk.readthedocs.io/en/v1.7.1/allensdk.brain_observatory.ecephys.ecephys_project_cache.html'>Allen SDK website</a>. We'll create an instance of `EcephysProjectCache` with a larger `timeout` value to ensure enough time is allowed for our session file to download below. \n",
    "\n",
    "Below we will execute `get_session_table()` on our `EcephysProjectCache` object which will return a dataframe with metadata on each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-639b362837c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Import allensdkd brain observatory packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallensdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain_observatory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecephys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecephys_project_cache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEcephysProjectCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallensdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain_observatory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecephys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecephys_project_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEcephysProjectWarehouseApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallensdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain_observatory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecephys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecephys_project_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrma_engine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRmaEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allensdk/brain_observatory/ecephys/ecephys_project_cache.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleITK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpynwb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallensdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarehouse_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pynwb/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhdmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNamespaceCatalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "# # Import packages necessary to plot behavior\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import allensdkd brain observatory packages\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_api import EcephysProjectWarehouseApi\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_api.rma_engine import RmaEngine\n",
    "import allensdk.brain_observatory.ecephys.visualization as ecvis\n",
    "\n",
    "# Assign where data will be stored\n",
    "manifest_path = 'manifest.json' \n",
    "\n",
    "# Create the EcephysProjectCache object\n",
    "cache = EcephysProjectCache(manifest=manifest_path,\n",
    "                            fetch_api=EcephysProjectWarehouseApi(RmaEngine(scheme=\"http\",host=\"api.brain-map.org\",timeout= 50 * 60)))    \n",
    "\n",
    "# Return all sessions available in this dataset\n",
    "sessions = cache.get_session_table()\n",
    "print('Total number of sessions: ' + str(len(sessions)))\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few columns that we may want to pay attention to for future analysis are the `full_genotype`, `unit_count`, and `ecephys_structure_acronyms`. \n",
    "\n",
    "In this dataset, a `unit` referes to an individual neuron that was recorded in the session. The `unit_count` refers to the total number of neurons recorded in a particular sesssion. As mentioned in the chapter introduction, three different genotypes of mice were used alongside the wildtype mice for these experiments. You can find the genotype under `full_genotype`. Lastly, you can find what structures the data in a session was collected from under `ecephys_structure_acronyms`.\n",
    "\n",
    "Below we will return the following information on our sessions: \n",
    "- how many sessions per genotype\n",
    "- the average number of units recorded per session\n",
    "- what brain structures were used in our sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes = sessions['full_genotype'].value_counts()\n",
    "avg_units = sessions['unit_count'].mean()\n",
    "\n",
    "brain_areas = []\n",
    "\n",
    "for idx,structure in sessions.iterrows():\n",
    "    for i in structure['ecephys_structure_acronyms']:\n",
    "        if i not in brain_areas:\n",
    "            brain_areas.append(i)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print('Genotype Count:')\n",
    "print(genotypes)\n",
    "\n",
    "print('\\nAverage Units:',avg_units)\n",
    "\n",
    "print('\\nAll brain areas:')\n",
    "print(brain_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we only want sessions where the data has recordings from primary visual cortex (VISp). We can do the following to create a session list that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_list = []\n",
    "\n",
    "for idx,structure_list in enumerate(sessions['ecephys_structure_acronyms']):\n",
    "    if 'VISp' in structure_list:\n",
    "        session_list.append(sessions.index[idx])   \n",
    "        \n",
    "print('There are '+str(len(session_list))+' sessions that meet this criteria:')\n",
    "print(session_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading a Single Session & the Structure of Session Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the session list to get the data we need. Unfortunately, we can only extract one experiment at a time, so if you want to do this for multiple experiments, you'll need to loop over the `get_session_data` method for your entire session_list. For example, your workflow might be:\n",
    "\n",
    "1. Extract one session.\n",
    "2. Look for units recorded from your brain region of interest in that session.\n",
    "3. Extract whatever metric you're interested in (e.g., firing rate).\n",
    "4. Append those values to a list of firing rates.\n",
    "5. Loop back around to the next session.\n",
    "\n",
    "The `get_session_data` downloads the `NWB` data file of our experiment session and returns a session object that contains data and metadata for a single session. For a full list of methods and attributes for an ecephys session object, please visit the <a href = 'https://allensdk.readthedocs.io/en/v1.7.1/allensdk.brain_observatory.ecephys.ecephys_session.html'> Allen SDK session module documentation</a>. Here, we'll just take one session as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The session files are very large files that will take some time to download depending on your connection speed. It is important that you do not stop the download as the cell is running because this will truncate the file and you will not be able to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download our single session data \n",
    "session = cache.get_session_data(session_list[1])\n",
    "print('Session downloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Single Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have downloaded the single session file, we can begin to explore our `EcephysSession` object. The `units` property of our session object returns a dataframe that contains the recorded activity of sorted neurons from a mouse brain. There are many metrics stored within `units` that can be used in your potential analyses. Some key metrics include:\n",
    "\n",
    "- **firing rate**: mean spike rate during the entire session\n",
    "- **presence ratio**: fraction of session when spikes are present\n",
    "- **ISI violations**: rate of refractory period violations\n",
    "- **peak_channel_id**: channel in which peak-to-trough amplitutde is maximized\n",
    "- **d'**: classification accuracy based on LDA\n",
    "- **SNR**: signal to noise ratio\n",
    "- **Maximum drift**: Maximum change in spike depth during recording\n",
    "- **Cumulative drift**: Cumulative change in spike depth during recording\n",
    "\n",
    "For a full list of methods and attributes that can be called on an `EcephysSession` object, please review the original documentation for the <a href = 'https://allensdk.readthedocs.io/en/v1.7.1/allensdk.brain_observatory.ecephys.ecephys_session.html'> ecephys_session module</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return units dataframe\n",
    "units_df = session.units\n",
    "units_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the recordings we use in our analysis are all reliable and of good quality, we will filter the data according to the signal-to-noise ratio (`snr`) and the `ISI_Violations` of our neurons. Below we will plot the distributions of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,3))\n",
    "\n",
    "# Signal to noise distribution\n",
    "ax[0].hist(units_df['snr'], bins=30)\n",
    "ax[0].set_xlabel('Signal to Noise Ratio')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "\n",
    "# ISI Violations\n",
    "ax[1].hist(units_df['isi_violations'], bins=30)\n",
    "ax[1].set_xlabel('Rate of Refractory Period Violations')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this tutorial, we will focus on units with `snr` values greater than 2 and `ISI_violation` values less than 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from units that fit criteria\n",
    "good_snr = units_df[units_df['snr']>2]\n",
    "good_units_df = good_snr[good_snr['isi_violations']<0.1]\n",
    "\n",
    "print('Number of units with good SNR and low ISI:',len(good_units_df))\n",
    "good_units_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Single Action Potential Waveforms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each session contains a dictionary of mean waveforms for all the units recorded in that session. They are stored inside a xarray DataArray where the `unit_id` are mapped to the mean spike waveform values. The dimensions of the DataArrays are `channel` and `time` which are recorded in microvolts and seconds, respectivley. For more information on `xarray.DataArray`, please visit the <a href = 'http://xarray.pydata.org/en/stable/generated/xarray.DataArray.html'> xarray original documentation</a>.\n",
    "\n",
    "To access the mean spike waveforms for all units in a session, use the attribute `mean_waveforms` on your `EcephysSession` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean_waveforms = session.mean_waveforms\n",
    "print('Total number of waveforms:',len(all_mean_waveforms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the mean waveforms of our units with the method `plot_mean_waveforms` from the ecephys visualization package. The method uses the `mean_waveforms` dictionary, `unit_id`'s, and `peak_channel_id`'s as arguments. For more information on this method, visit the `allensdk.brain_observatory.ecephys.visualization` package documentation on the <a href = 'https://allensdk.readthedocs.io/en/latest/allensdk.brain_observatory.ecephys.visualization.html'> Allen Brain Atlas website</a>.\n",
    "\n",
    "Below we will compare mean waveforms from units of different brain areas. We will be looking at one wavefrom from the `CA1`, `LP`, `DG`, `VISp`. We first need to create a list of unit_id's for the units we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Unit IDs of different brain areas of interest\n",
    "CA1_unit_ids = good_units_df[good_units_df['ecephys_structure_acronym'] == 'CA1'].index\n",
    "LP_unit_ids = good_units_df[good_units_df['ecephys_structure_acronym'] == 'LP'].index\n",
    "DG_unit_ids = good_units_df[good_units_df['ecephys_structure_acronym'] == 'DG'].index\n",
    "VISp_unit_ids = good_units_df[good_units_df['ecephys_structure_acronym'] == 'VISp'].index\n",
    "\n",
    "# Return first entry of our brain areas of interst\n",
    "first_CA1_units_ids = CA1_unit_ids[0]\n",
    "first_LP_units_ids = LP_unit_ids[0]\n",
    "first_DG_units_ids = DG_unit_ids[0]\n",
    "first_VISp_units_ids = VISp_unit_ids[0]\n",
    "uoi_ids = [first_CA1_units_ids, first_LP_units_ids, first_DG_units_ids, first_VISp_units_ids]\n",
    "\n",
    "# Return dataframe\n",
    "uoi_df = good_units_df.loc[uoi_ids]\n",
    "\n",
    "uoi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `unit_ids`, we can create our own dictionary that maps our units of interest to their `mean_waveforms` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create dictionary of waveforms that only include units of interest\n",
    "waveforms_oi = {}\n",
    "for ids in uoi_ids:\n",
    "    waveforms_oi[ids] = all_mean_waveforms[ids]\n",
    "\n",
    "# Create dictionary of peak channels that only include units of interest\n",
    "peak_channels_oi = {}\n",
    "for ids in uoi_ids:\n",
    "    peak_channels_oi[ids] = good_units_df.loc[ids, 'peak_channel_id']\n",
    "\n",
    "# Plot mean waveforms\n",
    "ecvis.plot_mean_waveforms(waveforms_oi, uoi_ids, peak_channels_oi)\n",
    "\n",
    "legend_list = list(uoi_df['ecephys_structure_acronym'] )\n",
    "plt.legend(legend_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "* [Allen Institute Tutorial Notebook](https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_session.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}