{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining Datasets with DANDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DANDI](https://www.dandiarchive.org/) is an open source data archive for neuroscience datasets, called **Dandisets**. DANDI allows scientists to submit and download neural datasets to promote research collaboration and consistent and transparent data standards. DANDI also provides a solution to the difficulties that come from housing data in the many other general domains (i.e. Dropbox, Google Drive, etc.). Usefully for our purposes here, many of the datasets on DANDI are in NWB format. If you'd like to know more about DANDI, check out the [DANDI handbook](https://www.dandiarchive.org/handbook/).\n",
    "\n",
    "There are two primary ways to work with Dandisets:\n",
    "1. You can **download the datasets**, either via the [DANDI Web Application](https://gui.dandiarchive.org/#/dandiset) or using the DANDI Python client below. If you download via the website, you'll need to create an account.\n",
    "2. You can **stream datasets directly** from DANDI. We'll show you how to do this online as well as on your local computer.\n",
    "\n",
    "Below, we demonstrate how to do both of these. For additional information on either of these methods, please refer to the [DANDI documentation](https://gui.dandiarchive.org/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Downloading Dandisets using Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will download [this dataset](https://gui.dandiarchive.org/#/dandiset/000006) from DANDI. This dataset contains 32-channel extracellular recordings from mouse cortex. We're using the [`download`](https://dandi.readthedocs.io/en/latest/cmdline/download.html) tool from dandi below.\n",
    "\n",
    "<mark>**Note:** Downloading this dataset may take several minutes, depending on your internet connection.</mark>\n",
    "\n",
    "<mark>**Note #2:** This step is *only possible* after completing the setup steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH                                         SIZE      DONE    DONE% CHECKSUM STATUS     MESSAGE          \n",
      "dandiset.yaml                                                                 skipped    already exists   \n",
      "sub-anm369962/sub-anm369962_ses-20170309.nwb                                  skipped    already exists   \n",
      "sub-anm369962/sub-anm369962_ses-20170316.nwb                                  skipped    already exists   \n",
      "sub-anm369962/sub-anm369962_ses-20170310.nwb                                  skipped    already exists   \n",
      "sub-anm369962/sub-anm369962_ses-20170314.nwb                                  skipped    already exists   \n",
      "sub-anm369962/sub-anm369962_ses-20170313.nwb                                  skipped    already exists   \n",
      "sub-anm369962/sub-anm369962_ses-20170317.nwb                                  skipped    already exists   \n",
      "sub-anm369963/sub-anm369963_ses-20170227.nwb                                  skipped    already exists   \n",
      "sub-anm369963/sub-anm369963_ses-20170226.nwb                                  skipped    already exists   \n",
      "sub-anm369963/sub-anm369963_ses-20170228.nwb                                  skipped    already exists   \n",
      "sub-anm369963/sub-anm369963_ses-20170301.nwb                                  skipped    already exists   \n",
      "sub-anm369963/sub-anm369963_ses-20170302.nwb                                  skipped    already exists   \n",
      "sub-anm369963/sub-anm369963_ses-20170306.nwb                                  skipped    already exists   \n",
      "sub-anm369963/sub-anm369963_ses-20170309.nwb                                  skipped    already exists   \n",
      "sub-anm369963/sub-anm369963_ses-20170310.nwb                                  skipped    already exists   \n",
      "sub-anm369964/sub-anm369964_ses-20170321.nwb                                  skipped    already exists   \n",
      "sub-anm369964/sub-anm369964_ses-20170320.nwb                                  skipped    already exists   \n",
      "sub-anm369964/sub-anm369964_ses-20170322.nwb                                  skipped    already exists   \n",
      "sub-anm369964/sub-anm369964_ses-20170323.nwb                                  skipped    already exists   \n",
      "sub-anm372793/sub-anm372793_ses-20170504.nwb                                  skipped    already exists   \n",
      "sub-anm372793/sub-anm372793_ses-20170508.nwb                                  skipped    already exists   \n",
      "sub-anm372793/sub-anm372793_ses-20170512.nwb                                  skipped    already exists   \n",
      "sub-anm372793/sub-anm372793_ses-20170513.nwb                                  skipped    already exists   \n",
      "sub-anm372794/sub-anm372794_ses-20170621.nwb                                  skipped    already exists   \n",
      "sub-anm372794/sub-anm372794_ses-20170622.nwb                                  skipped    already exists   \n",
      "sub-anm372793/sub-anm372793_ses-20170514.nwb                                  skipped    already exists   \n",
      "sub-anm372794/sub-anm372794_ses-20170624.nwb                                  skipped    already exists   \n",
      "sub-anm372794/sub-anm372794_ses-20170625.nwb                                  skipped    already exists   \n",
      "sub-anm372794/sub-anm372794_ses-20170626.nwb                                  skipped    already exists   \n",
      "sub-anm372794/sub-anm372794_ses-20170627.nwb                                  skipped    already exists   \n",
      "sub-anm372795/sub-anm372795_ses-20170715.nwb                                  skipped    already exists   \n",
      "sub-anm372795/sub-anm372795_ses-20170714.nwb                                  skipped    already exists   \n",
      "sub-anm372795/sub-anm372795_ses-20170716.nwb                                  skipped    already exists   \n",
      "sub-anm372795/sub-anm372795_ses-20170718.nwb                                  skipped    already exists   \n",
      "sub-anm372797/sub-anm372797_ses-20170617.nwb                                  skipped    already exists   \n",
      "sub-anm372904/sub-anm372904_ses-20170615.nwb                                  skipped    already exists   \n",
      "sub-anm372797/sub-anm372797_ses-20170615.nwb                                  skipped    already exists   \n",
      "sub-anm372904/sub-anm372904_ses-20170617.nwb                                  skipped    already exists   \n",
      "sub-anm372904/sub-anm372904_ses-20170616.nwb                                  skipped    already exists   \n",
      "sub-anm372904/sub-anm372904_ses-20170618.nwb                                  skipped    already exists   \n",
      "sub-anm372904/sub-anm372904_ses-20170619.nwb                                  skipped    already exists   \n",
      "sub-anm372905/sub-anm372905_ses-20170715.nwb                                  skipped    already exists   \n",
      "sub-anm372905/sub-anm372905_ses-20170716.nwb                                  skipped    already exists   \n",
      "sub-anm372905/sub-anm372905_ses-20170717.nwb                                  skipped    already exists   \n",
      "sub-anm372906/sub-anm372906_ses-20170608.nwb                                  skipped    already exists   \n",
      "sub-anm372906/sub-anm372906_ses-20170610.nwb                                  skipped    already exists   \n",
      "sub-anm372906/sub-anm372906_ses-20170611.nwb                                  skipped    already exists   \n",
      "sub-anm372906/sub-anm372906_ses-20170612.nwb                                  skipped    already exists   \n",
      "sub-anm372907/sub-anm372907_ses-20170608.nwb                                  skipped    already exists   \n",
      "sub-anm372907/sub-anm372907_ses-20170610.nwb                                  skipped    already exists   \n",
      "sub-anm372907/sub-anm372907_ses-20170613.nwb                                  skipped    already exists   \n",
      "sub-anm372907/sub-anm372907_ses-20170612.nwb                                  skipped    already exists   \n",
      "sub-anm372909/sub-anm372909_ses-20170520.nwb                                  skipped    already exists   \n",
      "sub-anm372909/sub-anm372909_ses-20170522.nwb                                  skipped    already exists   \n",
      "Summary:                                     0 Bytes   0 Bytes                54 skipped 54 already exists\n",
      "                                             +139.6 MB 0.00%                                              \n"
     ]
    }
   ],
   "source": [
    "from dandi.download import download as dandi_download\n",
    "import os \n",
    "\n",
    "# Set the URL for the DANDI file\n",
    "url = 'https://dandiarchive.org/dandiset/000006/draft'\n",
    "\n",
    "# Download the file into the current working directory\n",
    "# It will skip downloading any files you've already downloaded\n",
    "dandi_download([url], output_dir = os.getcwd(), existing = \"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cell above completes running, you will see a new folder üìÅ\"00006\" wherever you're running this notebook. Usefully, the code above will also print a list of individual NWB files that have been downloaded in this folder.\n",
    "\n",
    "**Once the data is done downloading, you're ready for the next step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Streaming the Dandiset\n",
    "\n",
    "The folks at NWB have also developed a clever way to stream Dandisets so that small bits of them can be viewed without downloading the entire dataset. This is particularly useful for very large datasets! **This step is a great option for large data sets, or if you have limited hard drive space, and/or if you are having issues with Option 1 above.**\n",
    "\n",
    "\n",
    "#### Streaming via the Dandihub\n",
    "The easiest way to stream data is via the DANDI Jupyter Hub (https://hub.dandiarchive.org/). There are setup steps for this in the introduction. The code below should work without a hitch in the Dandihub.\n",
    "\n",
    "#### Streaming locally, after configuring your environment\n",
    "With some configuration, you can stream data on your local computer. First, you need to set up your environment with the right version of a package called `h5py`. [There are instructions here for how to do that](https://pynwb.readthedocs.io/en/stable/tutorials/advanced_io/streaming.html#sphx-glr-tutorials-advanced-io-streaming-py). Once you're done, you can restart the kernel for this notebook, and run the code below.\n",
    "\n",
    "\n",
    "### Code for Data Streaming\n",
    "First, we need to figure out the correct URL for the dataset on the Amazon S3 storage system. There is a tool to do so within the dandiapi, which we'll use below to get the URL for one session from the data we downloaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dandiarchive.s3.amazonaws.com/blobs/43b/f3a/43bf3a81-4a0b-433f-b471-1f10303f9d35\n"
     ]
    }
   ],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "\n",
    "dandiset_id = '000006'  # ephys dataset from the Svoboda Lab\n",
    "filepath = 'sub-anm372795/sub-anm372795_ses-20170718.nwb'  # 450 kB file\n",
    "\n",
    "with DandiAPIClient() as client:\n",
    "    asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(filepath)\n",
    "    s3_path = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "    \n",
    "print(s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can read this path, but we'll stream it, rather than downloading it! The cell below will print some of the data about this experiment. It uses another package, [**PyNWB**](https://pynwb.readthedocs.io/en/stable/index.html), which is specifically designed to work with NWB files in Python. As you might expect, this won't be the last time we see this package. Below, we'll use the `NWBHDF5IO` class from this package, which will allow us to read NWB files.\n",
    "\n",
    "<mark>**Note**: The code below *will not work* unless you're on the Dandihub or have properly configured your environment. See above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "with NWBHDF5IO(s3_path, mode='r', load_namespaces=True, driver='ros3') as io:\n",
    "    nwbfile = io.read()\n",
    "    print(nwbfile)\n",
    "    print(nwbfile.acquisition['lick_times'].time_series['lick_left_times'].data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can use a fancy widget to create an interactive display of this dataset while we are streaming it. More on this [later](https://nwb4edu.github.io/Chapter_03/Interactive_NWB_Data_Exploration.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwbwidgets import nwb2widget\n",
    "\n",
    "nwb2widget(nwbfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section will go over the the structure of an NWBFile and how to access data from this new file type. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
